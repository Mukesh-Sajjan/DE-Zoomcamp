(base) mukesh@de-zoomcamp:~$ ls
Anaconda3-2022.10-Linux-x86_64.sh    anaconda3  data-engineering-zoomcamp
Anaconda3-2022.10-Linux-x86_64.sh.1  bin        snap
(base) mukesh@de-zoomcamp:~$ rm Anaconda3-2022.10-Linux-x86_64.sh.1
(base) mukesh@de-zoomcamp:~$ ls
Anaconda3-2022.10-Linux-x86_64.sh  bin                        snap
anaconda3                          data-engineering-zoomcamp
(base) mukesh@de-zoomcamp:~$ cd bin
(base) mukesh@de-zoomcamp:~/bin$ ls
docker-compose-linux-x86_64  ny-rides-mukesh-0f7f3bf2d754.json  terraform
(base) mukesh@de-zoomcamp:~/bin$ cd
(base) mukesh@de-zoomcamp:~$ cd data-engineering-zoomcamp
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp$ ls
README.md            week_1_basics_n_setup
after-sign-up.md     week_2_workflow_orchestration
arch_diagram.md      week_3_data_warehouse
asking-questions.md  week_4_analytics_engineering
cohorts              week_5_batch_processing
dataset.md           week_6_stream_processing
images               week_7_project
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp$ cd week_1_basics_n_setup
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup$ ls
1_terraform_gcp  2_docker_sql  README.md
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup$ cd 1_terraform_gcp
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp$ ls
1_terraform_overview.md  2_gcp_overview.md  README.md  terraform  windows.md
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp$ cd terraform
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ export GOOGLE_APPLICATION_CREDENTIALS=~/bin/ny-rides-mukesh-0f7f3bf2d754.json
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ gcloud auth activate-service-account --key-file $GOOGLE_APPLICATION_CREDENTIALS
Activated service account credentials for: [ny-rides-mukesh@ny-rides-mukesh.iam.gserviceaccount.com]
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ ls
README.md  main.tf  variables.tf
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ terraform init

Initializing the backend...

Successfully configured the backend "local"! Terraform will automatically
use this backend unless the backend configuration changes.

Initializing provider plugins...
- Finding latest version of hashicorp/google...
- Installing hashicorp/google v4.50.0...
- Installed hashicorp/google v4.50.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ terraform plan
var.project
  Your GCP Project ID

  Enter a value: ny-rides-mukesh


Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "ny-rides-mukesh"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + dataset {
              + target_types = (known after apply)

              + dataset {
                  + dataset_id = (known after apply)
                  + project_id = (known after apply)
                }
            }

          + routine {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + routine_id = (known after apply)
            }

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_ny-rides-mukesh"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }

      + website {
          + main_page_suffix = (known after apply)
          + not_found_page   = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ terraform apply
var.project
  Your GCP Project ID

  Enter a value: ny-rides-mukesh'


Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "ny-rides-mukesh'"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + dataset {
              + target_types = (known after apply)

              + dataset {
                  + dataset_id = (known after apply)
                  + project_id = (known after apply)
                }
            }

          + routine {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + routine_id = (known after apply)
            }

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_ny-rides-mukesh'"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }

      + website {
          + main_page_suffix = (known after apply)
          + not_found_page   = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
╷
│ Error: error: bucket name validation failed dtc_data_lake_ny-rides-mukesh'. See https://cloud.google.com/storage/docs/naming-buckets
│
│   with google_storage_bucket.data-lake-bucket,
│   on main.tf line 19, in resource "google_storage_bucket" "data-lake-bucket":
│   19: resource "google_storage_bucket" "data-lake-bucket" {
│
╵
╷
│ Error: Error creating Dataset: googleapi: Error 400: Invalid resource name projects/ny-rides-mukesh'; Project id: ny-rides-mukesh', badRequest
│
│   with google_bigquery_dataset.dataset,
│   on main.tf line 45, in resource "google_bigquery_dataset" "dataset":
│   45: resource "google_bigquery_dataset" "dataset" {
│
╵
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ (base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ terraform apply
-bash: syntax error near unexpected token `mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$'
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ var.project
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "ny-rides-mukesh'"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + dataset {
              + target_types = (known after apply)

              + dataset {
                  + dataset_id = (known after apply)
                  + project_id = (known after apply)
                }
            }

          + routine {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + routine_id = (known after apply)
            }

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_ny-rides-mukesh'"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }

      + website {
          + main_page_suffix = (known after apply)
          + not_found_page   = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
╷
│ Error: error: bucket name validation failed dtc_data_lake_ny-rides-mukesh'. See https://cloud.google.com/storage/docs/naming-buckets
│
│   with google_storage_bucket.data-lake-bucket,
│   on main.tf line 19, in resource "google_storage_bucket" "data-lake-bucket":
│   19: resource "google_storage_bucket" "data-lake-bucket" {
│
╵
╷
│ Error: Error creating Dataset: googleapi: Error 400: Invalid resource name projects/ny-rides-mukesh'; Project id: ny-rides-mukesh', badRequest
│
│   with google_bigquery_dataset.dataset,
│   on main.tf line 45, in resource "google_bigquery_dataset" "dataset":
│   45: resource "google_bigquery_dataset" "dataset" {
var.project: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$   Your GCP Project ID
Your: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$   Enter a value: ny-rides-mukesh'
>
>
> Terraform used the selected providers to generate the following execution plan.
> Resource actions are indicated with the following symbols:
>   + create
>
> Terraform will perform the following actions:
>
>   # google_bigquery_dataset.dataset will be created
>   + resource "google_bigquery_dataset" "dataset" {
>       + creation_time              = (known after apply)
>       + dataset_id                 = "trips_data_all"
>       + delete_contents_on_destroy = false
>       + etag                       = (known after apply)
>       + id                         = (known after apply)
>       + labels                     = (known after apply)
>       + last_modified_time         = (known after apply)
>       + location                   = "europe-west6"
>       + project                    = "ny-rides-mukesh'"
>       + self_link                  = (known after apply)
>
>       + access {
>           + domain         = (known after apply)
>           + group_by_email = (known after apply)
>           + role           = (known after apply)
>           + special_group  = (known after apply)
>           + user_by_email  = (known after apply)
>
>           + dataset {
>               + target_types = (known after apply)
>
>               + dataset {
>                   + dataset_id = (known after apply)
>                   + project_id = (known after apply)
>                 }
>             }
>
>           + routine {
>               + dataset_id = (known after apply)
>               + project_id = (known after apply)
>               + routine_id = (known after apply)
>             }
>
>           + view {
>               + dataset_id = (known after apply)
>               + project_id = (known after apply)
>               + table_id   = (known after apply)
>             }
>         }
>     }
>
>   # google_storage_bucket.data-lake-bucket will be created
>   + resource "google_storage_bucket" "data-lake-bucket" {
>       + force_destroy               = true
>       + id                          = (known after apply)
>       + location                    = "EUROPE-WEST6"
>       + name                        = "dtc_data_lake_ny-rides-mukesh'"
>       + project                     = (known after apply)
>       + public_access_prevention    = (known after apply)
>       + self_link                   = (known after apply)
>       + storage_class               = "STANDARD"
>       + uniform_bucket_level_access = true
>       + url                         = (known after apply)
>
>       + lifecycle_rule {
>           + action {
>               + type = "Delete"
>             }
>
>           + condition {
>               + age                   = 30
>               + matches_prefix        = []
>               + matches_storage_class = []
>               + matches_suffix        = []
>               + with_state            = (known after apply)
>             }
>         }
>
>       + versioning {
>           + enabled = true
>         }
>
>       + website {
>           + main_page_suffix = (known after apply)
>           + not_found_page   = (known after apply)
>         }
>     }
>
> Plan: 2 to add, 0 to change, 0 to destroy.
>
> Do you want to perform these actions?
>   Terraform will perform the actions described above.
>   Only 'yes' will be accepted to approve.
>
>   Enter a value: yes
>
> google_bigquery_dataset.dataset: Creating...
> google_storage_bucket.data-lake-bucket: Creating...
> ╷
> │ Error: error: bucket name validation failed dtc_data_lake_ny-rides-mukesh'. See https://cloud.google.com/storage/docs/naming-buckets
Enter: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   with google_storage_bucket.data-lake-bucket,
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   on main.tf line 19, in resource "google_storage_bucket" "data-lake-bucket":
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   19: resource "google_storage_bucket" "data-lake-bucket" {
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ ╵
╵: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ ╷
╷: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │ Error: Error creating Dataset: googleapi: Error 400: Invalid resource name projects/ny-rides-mukesh'; Project id: ny-rides-mukesh', badRequest
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   with google_bigquery_dataset.dataset,
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   on main.tf line 45, in resource "google_bigquery_dataset" "dataset":
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$ │   45: resource "google_bigquery_dataset" "dataset" {
│: command not found
(base) mukesh@de-zoomcamp:~/data-engineering-zoomcamp/week_1_basics_n_setup/1_terraform_gcp/terraform$
